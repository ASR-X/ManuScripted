{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Essay Inspiration Generator",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ASR-X/ManuScripted/blob/main/backend/Essay_Inspiration_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LviEIhR5NsXe"
      },
      "source": [
        "# Initialization Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb7Jq3zQ-H23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90c1cc6f-51b3-4b25-becf-83bbfdde43c9"
      },
      "source": [
        "#@title\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "!pip install fastapi pyngrok uvicorn nest-asyncio google-cloud-texttospeech gpt-2-simple\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip /content/ngrok-stable-linux-amd64.zip\n",
        "!./ngrok authtoken 1ooUEkPs7SzF16HgLhHjnsrx8SQ_4zUJGFX5gjWgFj8MH1gFA"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.7/dist-packages (0.63.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.7/dist-packages (5.0.4)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.7/dist-packages (0.13.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "Requirement already satisfied: google-cloud-texttospeech in /usr/local/lib/python3.7/dist-packages (2.2.0)\n",
            "Requirement already satisfied: gpt-2-simple in /usr/local/lib/python3.7/dist-packages (0.7.2)\n",
            "Requirement already satisfied: pydantic<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from fastapi) (1.8.1)\n",
            "Requirement already satisfied: starlette==0.13.6 in /usr/local/lib/python3.7/dist-packages (from fastapi) (0.13.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (3.13)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.7/dist-packages (from uvicorn) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from uvicorn) (3.7.4.3)\n",
            "Requirement already satisfied: click==7.* in /usr/local/lib/python3.7/dist-packages (from uvicorn) (7.1.2)\n",
            "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-texttospeech) (1.26.1)\n",
            "Requirement already satisfied: libcst>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from google-cloud-texttospeech) (0.3.17)\n",
            "Requirement already satisfied: proto-plus>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-texttospeech) (1.18.1)\n",
            "Requirement already satisfied: toposort in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (1.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.0->google-cloud-texttospeech) (20.9)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.0->google-cloud-texttospeech) (1.15.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.0->google-cloud-texttospeech) (2018.9)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.0->google-cloud-texttospeech) (3.12.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.0->google-cloud-texttospeech) (54.1.2)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.0->google-cloud-texttospeech) (1.27.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.0->google-cloud-texttospeech) (1.53.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.29.0; extra == \"grpc\" in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.22.0->google-cloud-texttospeech) (1.32.0)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from libcst>=0.2.5->google-cloud-texttospeech) (0.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core[grpc]<2.0.0dev,>=1.22.0->google-cloud-texttospeech) (2.4.7)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.22.0->google-cloud-texttospeech) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.22.0->google-cloud-texttospeech) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.22.0->google-cloud-texttospeech) (4.7.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from typing-inspect>=0.4.0->libcst>=0.2.5->google-cloud-texttospeech) (0.4.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core[grpc]<2.0.0dev,>=1.22.0->google-cloud-texttospeech) (0.4.8)\n",
            "--2021-03-21 16:26:18--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.197.133.26, 52.70.180.11, 34.205.198.58, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.197.133.26|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.2’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  14.1MB/s    in 0.9s    \n",
            "\n",
            "2021-03-21 16:26:19 (14.1 MB/s) - ‘ngrok-stable-linux-amd64.zip.2’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  /content/ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwGSlPirG6WH"
      },
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/My First Project-ca53a835bffe.json\"\n",
        "def synthesize_text(text):\n",
        "    from google.cloud import texttospeech\n",
        "    client = texttospeech.TextToSpeechClient()\n",
        "    input_text = texttospeech.SynthesisInput(text=text)\n",
        "    voice = texttospeech.VoiceSelectionParams(\n",
        "        language_code=\"en-US\",\n",
        "        name=\"en-US-Wavenet-F\",\n",
        "        ssml_gender=texttospeech.SsmlVoiceGender.FEMALE,)\n",
        "    audio_config = texttospeech.AudioConfig(audio_encoding=texttospeech.AudioEncoding.MP3)#LINEAR16)\n",
        "    response = client.synthesize_speech(request={\"input\": input_text, \"voice\": voice, \"audio_config\": audio_config})\n",
        "    with open(\"output.mp3\", \"wb\") as out:\n",
        "        out.write(response.audio_content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UD00jq_XpoY"
      },
      "source": [
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
        "* `774M`: the \"large\" model, 3GB on disk.\n",
        "* `1558M`: the \"extra large\", true model. Will not work if a K80/P4 GPU is attached to the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_"
      },
      "source": [
        "#@title\n",
        "%%capture\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2 \n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "model_size='124M' \n",
        "model_name = model_size\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnayJ9mQxmKs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "2757fbdc-01fe-4967-c0a7-de6d0adb9d0f"
      },
      "source": [
        "#@title\n",
        "gpt2.download_gpt2(model_name=model_name)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 569Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:01, 917kit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 755Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001:   1%|                 | 3.15M/498M [00:01<05:14, 1.57Mit/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-_mJOxuHD2u"
      },
      "source": [
        "\"\"\"#@title\n",
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess(threads=1)\n",
        "gpt2.load_gpt2(sess, model_name=model_name)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vajP1LF0p5n-"
      },
      "source": [
        "\"\"\"#@title\n",
        "def inspiration(prompt):\n",
        "  gpt2.generate(sess,\n",
        "                    model_name=model_name,\n",
        "                    prefix=prompt,\n",
        "                    length=150,\n",
        "                    temperature=0.75,\n",
        "                    top_p=0.9,\n",
        "                    nsamples=3,\n",
        "                    batch_size=3,\n",
        "                    return_as_list=True\n",
        "  )\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gCKdgXJWPny"
      },
      "source": [
        "#@title\n",
        "\"\"\"\n",
        "global sess\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess(threads=1)\n",
        "gpt2.load_gpt2(sess, model_name=model_name)\n",
        "global graph\n",
        "graph = tf.get_default_graph() \n",
        "global pog \n",
        "pog=graph\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aESyMB31N_I-"
      },
      "source": [
        "# Inspiration Flask Server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttFQI9nIHywX"
      },
      "source": [
        "flask=\"\"\"import json\n",
        "from flask import Flask,request, send_file\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import re\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app) \n",
        "\n",
        "\n",
        "@app.route(\"/\")\n",
        "def root():\n",
        "    return 'test -- alive'\n",
        "\n",
        "\n",
        "\n",
        "@app.route('/inspire', methods=['POST'])\n",
        "def getInspiration():\n",
        "    global sess\n",
        "    content = request.json\n",
        "    g=content[\"ops\"][0][\"insert\"]#get essay\n",
        "    print(g)\n",
        "    global pog \n",
        "\n",
        "    graph = pog\n",
        "    with graph.as_default():\n",
        "      res=gpt2.generate(sess,\n",
        "                      model_name=model_name,\n",
        "                      prefix=g,\n",
        "                      length=150,\n",
        "                      temperature=0.75,\n",
        "                      top_p=0.9,\n",
        "                      nsamples=3,\n",
        "                      batch_size=3,\n",
        "                      return_as_list=True\n",
        "      )#get 3 samples\n",
        "    ret=[]\n",
        "\n",
        "    for r in res:\n",
        "      re.sub(r\"(?<=[a-z])\\r?\\n\",\" \", r)\n",
        "\n",
        "      ret.append(r[len(g):])#trim off input\n",
        "      \n",
        "    print(ret)\n",
        "    rett=[]\n",
        "    for r in ret:\n",
        "      print(r)\n",
        "\n",
        "      try:\n",
        "        rett.append(re.findall(\"^.*?[.!?](?=\\s[A-Z]|\\s?$)(?!.*\\))\",r)[0])#get first sentence\n",
        "      except:\n",
        "        rett.append(r)\n",
        "    return \"\\n\\n\".join(rett)#seperated by double linebreak\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD5ztvYPKgp-"
      },
      "source": [
        "from fastapi import FastAPI\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel\n",
        "from fastapi.responses import FileResponse\n",
        "import gpt_2_simple as gpt2\n",
        "import tensorflow as tf\n",
        "import re\n",
        "\n",
        "class EssayIn(BaseModel):\n",
        "    essay : str\n",
        "\n",
        "class ScoreOut(BaseModel):\n",
        "    in1: str\n",
        "    in2: str\n",
        "    in3: str\n",
        "\n",
        "\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins='*',\n",
        "    allow_credentials=True,\n",
        "    allow_methods='*',\n",
        "    allow_headers='*',\n",
        ")\n",
        "\n",
        "\n",
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess(threads=1)\n",
        "gpt2.load_gpt2(sess, model_name=model_name)\n",
        "\n",
        "@app.api_route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "async def root():\n",
        "    return 'alive'\n",
        "\n",
        "@app.post('/inspire', response_model=ScoreOut)\n",
        "async def getInspiration(essayin: EssayIn):\n",
        "    global sess\n",
        "    content = essayin.essay\n",
        "    g=content#[\"ops\"][0][\"insert\"]#get essay\n",
        "    print(g)\n",
        "\n",
        "    res=gpt2.generate(sess,\n",
        "                      model_name=model_name,\n",
        "                      prefix=g,\n",
        "                      length=150,\n",
        "                      temperature=0.75,\n",
        "                      top_p=0.9,\n",
        "                      nsamples=3,\n",
        "                      batch_size=3,\n",
        "                      return_as_list=True\n",
        "      )#get 3 samples\n",
        "    ret=[]\n",
        "\n",
        "    for r in res:\n",
        "      re.sub(r\"(?<=[a-z])\\r?\\n\",\" \", r)\n",
        "\n",
        "      ret.append(r[len(g):])#trim off input\n",
        "      \n",
        "    print(ret)\n",
        "    rett=[]\n",
        "    for r in ret:\n",
        "      print(r)\n",
        "\n",
        "      try:\n",
        "        rett.append(re.findall(\"^.*?[.!?](?=\\s[A-Z]|\\s?$)(?!.*\\))\",r)[0])#get first sentence\n",
        "      except:\n",
        "        rett.append(r)\n",
        "    return {\"in1\":rett[0],\"in2\":rett[1],\"in3\":rett[2]}#seperated by double linebreak\n",
        "\n",
        "@app.post(\"/tts\")\n",
        "async def getSpeech():\n",
        "    content = request.data#request.json\n",
        "    g=content.decode(\"utf-8\")#g=content[\"ops\"][0][\"insert\"]\n",
        "    print(synthesize_text(g))\n",
        "    return FileResponse(\"/content/output.mp3\", media_type='audio/mpeg',filename=file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJbVgxNMKkD_"
      },
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "ngrok_tunnel = ngrok.connect(80, bind_tls=True)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB8ET89J4YtP"
      },
      "source": [
        "# Convert DOCX to HTML\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-ef5DhT4fQK"
      },
      "source": [
        "!pip install fastapi nest-asyncio flask_ngrok mammoth\n",
        "#!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "#!unzip /content/ngrok-stable-linux-amd64.zip\n",
        "#!./ngrok authtoken 1ooUEkPs7SzF16HgLhHjnsrx8SQ_4zUJGFX5gjWgFj8MH1gFA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTZ-i4n74b4C"
      },
      "source": [
        "import json\n",
        "from flask import Flask,request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "import re\n",
        "import base64\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app) \n",
        "\n",
        "@app.route('/convertdocx', methods=['POST'])\n",
        "def convertDocx():\n",
        "      print(base64.b64decode(request.json['doc']))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3SGLxlvPh_0"
      },
      "source": [
        "Parse All Items into Labels and Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI3ZmDu-Pgp6"
      },
      "source": [
        "import requests\n",
        "\n",
        "URL = \"https://v1.nocodeapi.com/asrx/webflow/arvZVdciEcIdtZsO\"\n",
        "r = requests.get(url = URL)\n",
        "\n",
        "print(r.json())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}